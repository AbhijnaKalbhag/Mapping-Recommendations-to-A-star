{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "78bX81bpicgQ",
        "outputId": "527bc966-b745-4fc5-92b6-54c8720f15fc"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models import Word2Vec\n",
        "import random\n",
        "import matplotlib.patches as mpatches\n",
        "from heapq import heappush, heappop\n",
        "\n",
        "# Create a OneHotEncoder instance\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "csv_file = \"amazon.csv\"\n",
        "\n",
        "# Read the CSV data and create a dictionary of products\n",
        "products_dict = {}\n",
        "with open(csv_file, mode='r', encoding='utf-8') as file:\n",
        "    csv_reader = csv.DictReader(file)\n",
        "    for row in csv_reader:\n",
        "        # Extract and clean the rating_count\n",
        "        try:\n",
        "            rating_count = int(row['rating_count'].replace(',', '')) if row['rating_count'] else 0\n",
        "        except ValueError:\n",
        "            rating_count = 0\n",
        "\n",
        "        # Extract and clean the rating\n",
        "        try:\n",
        "            rating = float(row['rating'])\n",
        "        except ValueError:\n",
        "            rating = 0.0\n",
        "\n",
        "        # Create a dictionary for each product\n",
        "        product_details = {\n",
        "            'product_id': row['product_id'],\n",
        "            'product_name': row['product_name'],\n",
        "            'category': row['category'],\n",
        "            'rating': rating,\n",
        "            'rating_count': rating_count,\n",
        "            'about_product': row['about_product']\n",
        "        }\n",
        "        # Use product_id as the key for the products dictionary\n",
        "        products_dict[row['product_id']] = product_details\n",
        "\n",
        "# Print available product IDs\n",
        "print(\"Available product IDs:\", list(products_dict.keys())[:10])  # Print first 10 product IDs for checking\n",
        "\n",
        "# Construct the grid\n",
        "num_products = len(products_dict)\n",
        "grid_size = int(np.ceil(np.sqrt(num_products)))\n",
        "grid = np.empty((grid_size, grid_size), dtype=object)\n",
        "\n",
        "# Calculate row indices using hybrid filtering\n",
        "categories = np.array([p['category'] for p in products_dict.values()]).reshape(-1, 1)\n",
        "category_encoded = encoder.fit_transform(categories)\n",
        "\n",
        "features = np.array([[p['rating'], p['rating_count']] for p in products_dict.values()])\n",
        "features = np.concatenate((category_encoded, features), axis=1)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "row_indices = scaler.fit_transform(features)\n",
        "\n",
        "# Calculate column indices using Word2Vec embeddings for better semantic similarity\n",
        "corpus = [p['about_product'].split() for p in products_dict.values()]\n",
        "word2vec_model = Word2Vec(sentences=corpus, vector_size=50, window=5, min_count=1, workers=4)\n",
        "product_vectors = np.array([np.mean([word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
        "                                    or [np.zeros(50)], axis=0) for words in corpus])\n",
        "\n",
        "column_indices = scaler.fit_transform(product_vectors)\n",
        "\n",
        "# Normalize indices to fit within grid size\n",
        "row_indices = (row_indices[:, 0] * (grid_size - 1)).astype(int)\n",
        "column_indices = (column_indices[:, 0] * (grid_size - 1)).astype(int)\n",
        "\n",
        "# Shuffle the product IDs to ensure a random distribution\n",
        "product_ids = list(products_dict.keys())\n",
        "random.shuffle(product_ids)\n",
        "\n",
        "# Place products in the grid based on normalized indices\n",
        "for idx, product_id in enumerate(product_ids):\n",
        "    row = row_indices[idx]\n",
        "    col = column_indices[idx]\n",
        "    while grid[row, col] is not None:\n",
        "        col = (col + 1) % grid_size\n",
        "        if col == 0:\n",
        "            row = (row + 1) % grid_size\n",
        "    grid[row, col] = product_id\n",
        "    print(f\"Product ID: {product_id}, Row: {row}, Column: {col}\")  # Print statement for checking\n",
        "\n",
        "# A* search functions\n",
        "def calculate_similarity(product1, product2):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    text_vectors = vectorizer.fit_transform([product1['about_product'], product2['about_product']])\n",
        "    cosine_sim = cosine_similarity(text_vectors[0:1], text_vectors[1:2])[0][0]\n",
        "    rating_similarity = min(product1['rating'], product2['rating']) / max(product1['rating'], product2['rating'])\n",
        "    rating_count_similarity = min(product1['rating_count'], product2['rating_count']) / max(product1['rating_count'], product2['rating_count'])\n",
        "    similarity_score = cosine_sim + rating_similarity + rating_count_similarity\n",
        "    return similarity_score\n",
        "\n",
        "def a_star_search_recommendations(start, grid, products_dict, max_recommendations=10):\n",
        "    def heuristic(product1, product2):\n",
        "        return calculate_similarity(products_dict[product1], products_dict[product2])\n",
        "\n",
        "    def get_neighbors(row, col):\n",
        "        neighbors = []\n",
        "        if row > 0: neighbors.append((row - 1, col))\n",
        "        if row < grid_size - 1: neighbors.append((row + 1, col))\n",
        "        if col > 0: neighbors.append((row, col - 1))\n",
        "        if col < grid_size - 1: neighbors.append((row, col + 1))\n",
        "        return neighbors\n",
        "\n",
        "    start_position = None\n",
        "    for i in range(grid_size):\n",
        "        for j in range(grid_size):\n",
        "            if grid[i, j] == start:\n",
        "                start_position = (i, j)\n",
        "                break\n",
        "        if start_position:\n",
        "            break\n",
        "\n",
        "    open_set = []\n",
        "    heappush(open_set, (0, start_position))\n",
        "    came_from = {}\n",
        "    g_score = {pos: float('inf') for row in range(grid_size) for pos in [(row, col) for col in range(grid_size)]}\n",
        "    g_score[start_position] = 0\n",
        "    f_score = {pos: float('inf') for row in range(grid_size) for pos in [(row, col) for col in range(grid_size)]}\n",
        "    f_score[start_position] = 0\n",
        "\n",
        "    recommendations = []\n",
        "    path = []\n",
        "    while open_set and len(recommendations) < max_recommendations:\n",
        "        _, current = heappop(open_set)\n",
        "        path.append(current)\n",
        "        current_product = grid[current[0], current[1]]\n",
        "        if current_product not in recommendations:\n",
        "            recommendations.append(current_product)\n",
        "        neighbors = get_neighbors(current[0], current[1])\n",
        "        for neighbor in neighbors:\n",
        "            neighbor_product = grid[neighbor[0], neighbor[1]]\n",
        "            if neighbor_product:\n",
        "                tentative_g_score = g_score[current] + calculate_similarity(products_dict[current_product], products_dict[neighbor_product])\n",
        "                if tentative_g_score < g_score[neighbor]:\n",
        "                    came_from[neighbor] = current\n",
        "                    g_score[neighbor] = tentative_g_score\n",
        "                    f_score[neighbor] = g_score[neighbor] + heuristic(current_product, neighbor_product)\n",
        "                    heappush(open_set, (f_score[neighbor], neighbor))\n",
        "\n",
        "    return recommendations, path\n",
        "\n",
        "# Choose a valid start product ID from the printed list\n",
        "start_product_id = \"B00P93X0VO\"  # Use the first available product ID\n",
        "recommendations = a_star_search_recommendations(start_product_id, grid, products_dict, max_recommendations=10)\n",
        "print(\"Recommended products:\", recommendations)\n",
        "\n",
        "# Visualization with improved clarity\n",
        "plt.figure(figsize=(50, 50))\n",
        "plt.imshow(np.full((grid_size, grid_size), np.nan), cmap='viridis', interpolation='none')  # Empty grid\n",
        "plt.title('Product Grid Based on Hybrid Filtering and Embeddings')\n",
        "\n",
        "# Define colors for categories\n",
        "categories_unique = list(set(p['category'] for p in products_dict.values()))\n",
        "category_colors = {category: plt.cm.tab20(i / len(categories_unique)) for i, category in enumerate(categories_unique)}\n",
        "\n",
        "for i in range(grid_size):\n",
        "    plt.axhline(i - 0.5, color='gray', linewidth=0.5)\n",
        "    plt.axvline(i - 0.5, color='gray', linewidth=0.5)\n",
        "\n",
        "for (row, col), product_id in np.ndenumerate(grid):\n",
        "    if product_id is not None:\n",
        "        product = products_dict[product_id]\n",
        "        color = category_colors[product['category']]\n",
        "        plt.text(col, row, product_id, ha='center', va='center', fontsize=8, bbox=dict(facecolor=color, edgecolor='black', boxstyle='round,pad=0.3'))\n",
        "\n",
        "# Create a legend with category colors\n",
        "handles = [mpatches.Patch(color=color, label=category) for category, color in category_colors.items()]\n",
        "plt.legend(handles=handles, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RYSLGVLOwugO",
        "outputId": "90f39301-a58d-4296-e634-8cf8f3c8e572"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models import Word2Vec\n",
        "import random\n",
        "import matplotlib.patches as mpatches\n",
        "from heapq import heappush, heappop\n",
        "\n",
        "# Create a OneHotEncoder instance\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "csv_file = \"amazon.csv\"\n",
        "\n",
        "# Read the CSV data and create a dictionary of products\n",
        "products_dict = {}\n",
        "with open(csv_file, mode='r', encoding='utf-8') as file:\n",
        "    csv_reader = csv.DictReader(file)\n",
        "    for row in csv_reader:\n",
        "        # Extract and clean the rating_count\n",
        "        try:\n",
        "            rating_count = int(row['rating_count'].replace(',', '')) if row['rating_count'] else 0\n",
        "        except ValueError:\n",
        "            rating_count = 0\n",
        "\n",
        "        # Extract and clean the rating\n",
        "        try:\n",
        "            rating = float(row['rating'])\n",
        "        except ValueError:\n",
        "            rating = 0.0\n",
        "\n",
        "        # Create a dictionary for each product\n",
        "        product_details = {\n",
        "            'product_id': row['product_id'],\n",
        "            'product_name': row['product_name'],\n",
        "            'category': row['category'],\n",
        "            'rating': rating,\n",
        "            'rating_count': rating_count,\n",
        "            'about_product': row['about_product']\n",
        "        }\n",
        "        # Use product_id as the key for the products dictionary\n",
        "        products_dict[row['product_id']] = product_details\n",
        "\n",
        "# Print available product IDs\n",
        "print(\"Available product IDs:\", list(products_dict.keys())[:10])  # Print first 10 product IDs for checking\n",
        "\n",
        "# Construct the grid\n",
        "num_products = len(products_dict)\n",
        "grid_size = int(np.ceil(np.sqrt(num_products)))\n",
        "grid = np.empty((grid_size, grid_size), dtype=object)\n",
        "\n",
        "# Calculate row indices using hybrid filtering\n",
        "categories = np.array([p['category'] for p in products_dict.values()]).reshape(-1, 1)\n",
        "category_encoded = encoder.fit_transform(categories)\n",
        "\n",
        "features = np.array([[p['rating'], p['rating_count']] for p in products_dict.values()])\n",
        "features = np.concatenate((category_encoded, features), axis=1)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "row_indices = scaler.fit_transform(features)\n",
        "\n",
        "# Calculate column indices using Word2Vec embeddings for better semantic similarity\n",
        "corpus = [p['about_product'].split() for p in products_dict.values()]\n",
        "word2vec_model = Word2Vec(sentences=corpus, vector_size=50, window=5, min_count=1, workers=4)\n",
        "product_vectors = np.array([np.mean([word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
        "                                    or [np.zeros(50)], axis=0) for words in corpus])\n",
        "\n",
        "column_indices = scaler.fit_transform(product_vectors)\n",
        "\n",
        "# Normalize indices to fit within grid size\n",
        "normalized_row_indices = row_indices[:, 0]\n",
        "normalized_col_indices = column_indices[:, 0]\n",
        "row_indices = (normalized_row_indices * (grid_size - 1)).astype(int)\n",
        "column_indices = (normalized_col_indices * (grid_size - 1)).astype(int)\n",
        "\n",
        "# Shuffle the product IDs to ensure a random distribution\n",
        "product_ids = list(products_dict.keys())\n",
        "random.shuffle(product_ids)\n",
        "\n",
        "# Place products in the grid based on normalized indices\n",
        "for idx, product_id in enumerate(product_ids):\n",
        "    row = row_indices[idx]\n",
        "    col = column_indices[idx]\n",
        "    while grid[row, col] is not None:\n",
        "        col = (col + 1) % grid_size\n",
        "        if col == 0:\n",
        "            row = (row + 1) % grid_size\n",
        "    grid[row, col] = product_id\n",
        "    # print(f\"Product ID: {product_id}, Normalized Row: {normalized_row_indices[idx]:.2f}, Normalized Column: {normalized_col_indices[idx]:.2f}\")\n",
        "\n",
        "# A* search functions\n",
        "def calculate_similarity(product1, product2):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    text_vectors = vectorizer.fit_transform([product1['about_product'], product2['about_product']])\n",
        "    cosine_sim = cosine_similarity(text_vectors[0:1], text_vectors[1:2])[0][0]\n",
        "    rating_similarity = min(product1['rating'], product2['rating']) / max(product1['rating'], product2['rating'])\n",
        "    rating_count_similarity = min(product1['rating_count'], product2['rating_count']) / max(product1['rating_count'], product2['rating_count'])\n",
        "    similarity_score = cosine_sim + rating_similarity + rating_count_similarity\n",
        "    return similarity_score\n",
        "\n",
        "def a_star_search_recommendations(start, grid, products_dict, max_recommendations=10):\n",
        "    def heuristic(product1, product2):\n",
        "        return calculate_similarity(products_dict[product1], products_dict[product2])\n",
        "\n",
        "    def get_neighbors(row, col):\n",
        "        neighbors = []\n",
        "        if row > 0: neighbors.append((row - 1, col))\n",
        "        if row < grid_size - 1: neighbors.append((row + 1, col))\n",
        "        if col > 0: neighbors.append((row, col - 1))\n",
        "        if col < grid_size - 1: neighbors.append((row, col + 1))\n",
        "        return neighbors\n",
        "\n",
        "    start_position = None\n",
        "    for i in range(grid_size):\n",
        "        for j in range(grid_size):\n",
        "            if grid[i, j] == start:\n",
        "                start_position = (i, j)\n",
        "                break\n",
        "        if start_position:\n",
        "            break\n",
        "\n",
        "    open_set = []\n",
        "    heappush(open_set, (0, start_position))\n",
        "    came_from = {}\n",
        "    g_score = {pos: float('inf') for row in range(grid_size) for pos in [(row, col) for col in range(grid_size)]}\n",
        "    g_score[start_position] = 0\n",
        "    f_score = {pos: float('inf') for row in range(grid_size) for pos in [(row, col) for col in range(grid_size)]}\n",
        "    f_score[start_position] = 0\n",
        "\n",
        "    recommendations = []\n",
        "    path = []\n",
        "    while open_set and len(recommendations) < max_recommendations:\n",
        "        _, current = heappop(open_set)\n",
        "        path.append(current)\n",
        "        current_product = grid[current[0], current[1]]\n",
        "        if current_product not in recommendations:\n",
        "            recommendations.append(current_product)\n",
        "        neighbors = get_neighbors(current[0], current[1])\n",
        "        for neighbor in neighbors:\n",
        "            neighbor_product = grid[neighbor[0], neighbor[1]]\n",
        "            if neighbor_product:\n",
        "                tentative_g_score = g_score[current] + calculate_similarity(products_dict[current_product], products_dict[neighbor_product])\n",
        "                if tentative_g_score < g_score[neighbor]:\n",
        "                    came_from[neighbor] = current\n",
        "                    g_score[neighbor] = tentative_g_score\n",
        "                    f_score[neighbor] = g_score[neighbor] + heuristic(current_product, neighbor_product)\n",
        "                    heappush(open_set, (f_score[neighbor], neighbor))\n",
        "\n",
        "    return recommendations, path\n",
        "\n",
        "# Choose a valid start product ID from the printed list\n",
        "start_product_id = \"B00P93X0VO\"  # Use the first available product ID\n",
        "recommendations, path = a_star_search_recommendations(start_product_id, grid, products_dict, max_recommendations=10)\n",
        "print(\"Recommended products:\", recommendations)\n",
        "\n",
        "# Visualization with A* path\n",
        "plt.figure(figsize=(40, 40))\n",
        "plt.imshow(np.full((grid_size, grid_size), np.nan), cmap='viridis', interpolation='none')  # Empty grid\n",
        "plt.title('Product Grid Based on Hybrid Filtering and Embeddings')\n",
        "\n",
        "# Define colors for categories\n",
        "categories_unique = list(set(p['category'] for p in products_dict.values()))\n",
        "category_colors = {category: plt.cm.tab20(i / len(categories_unique)) for i, category in enumerate(categories_unique)}\n",
        "\n",
        "for i in range(grid_size):\n",
        "    plt.axhline(i - 0.5, color='gray', linewidth=0.5)\n",
        "    plt.axvline(i - 0.5, color='gray', linewidth=0.5)\n",
        "\n",
        "for (row, col), product_id in np.ndenumerate(grid):\n",
        "    if product_id is not None:\n",
        "        product = products_dict[product_id]\n",
        "        color = category_colors[product['category']]\n",
        "        plt.text(col, row, product_id, ha='center', va='center', fontsize=8, bbox=dict(facecolor=color, edgecolor='black', boxstyle='round,pad=0.3'))\n",
        "\n",
        "# Highlight the A* path\n",
        "for (row, col) in path:\n",
        "    plt.plot(col, row, 'ro')  # Mark the path with red dots\n",
        "\n",
        "# Create a legend with category colors\n",
        "handles = [mpatches.Patch(color=color, label=category) for category, color in category_colors.items()]\n",
        "plt.legend(handles=handles, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
        "\n",
        "plt.xlabel('Embedding-based Column Index')\n",
        "plt.ylabel('Hybrid Filtering-based Row Index')\n",
        "plt.grid(False)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aEhxPiJyvP1",
        "outputId": "950ebadd-cf1e-4f2b-fced-2617e10c0653"
      },
      "outputs": [],
      "source": [
        "# Print recommended product details\n",
        "print(\"Recommended products:\")\n",
        "for product_id in recommendations:\n",
        "    product = products_dict[product_id]\n",
        "    print(f\"Product ID: {product['product_id']}\")\n",
        "    print(f\"Product Name: {product['product_name']}  \")\n",
        "    print(f\"Category: {product['category']}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbHlki3Gj69P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ob8sCrocwurO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yz_hKrH6wutq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WDtRBPHLwuw_",
        "outputId": "b05ab71a-c698-442a-9b4e-02a03c39acf9"
      },
      "outputs": [],
      "source": [
        "# *************   post dataset change **************************\n",
        "import csv\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models import Word2Vec\n",
        "import random\n",
        "import matplotlib.patches as mpatches\n",
        "from heapq import heappush, heappop\n",
        "\n",
        "# Create a OneHotEncoder instance\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "csv_file = \"amazon.csv\"\n",
        "\n",
        "# Read the CSV data and create a dictionary of products\n",
        "products_dict = {}\n",
        "with open(csv_file, mode='r', encoding='utf-8') as file:\n",
        "    csv_reader = csv.DictReader(file)\n",
        "    for row in csv_reader:\n",
        "        # Extract and clean the rating_count\n",
        "        try:\n",
        "            rating_count = int(row['rating_count'].replace(',', '')) if row['rating_count'] else 0\n",
        "        except ValueError:\n",
        "            rating_count = 0\n",
        "\n",
        "        # Extract and clean the rating\n",
        "        try:\n",
        "            rating = float(row['rating'])\n",
        "        except ValueError:\n",
        "            rating = 0.0\n",
        "\n",
        "        # Create a dictionary for each product\n",
        "        product_details = {\n",
        "            'product_id': row['product_id'],\n",
        "            'product_name': row['product_name'],\n",
        "            'category': row['category'],\n",
        "            'rating': rating,\n",
        "            'rating_count': rating_count,\n",
        "            'about_product': row['about_product']\n",
        "        }\n",
        "        # Use product_id as the key for the products dictionary\n",
        "        products_dict[row['product_id']] = product_details\n",
        "\n",
        "# Print available product IDs\n",
        "print(\"Available product IDs:\", list(products_dict.keys())[:10])  # Print first 10 product IDs for checking\n",
        "\n",
        "# Construct the grid\n",
        "num_products = len(products_dict)\n",
        "grid_size = int(np.ceil(np.sqrt(num_products)))\n",
        "grid = np.empty((grid_size, grid_size), dtype=object)\n",
        "\n",
        "# Calculate row indices using hybrid filtering\n",
        "categories = np.array([p['category'] for p in products_dict.values()]).reshape(-1, 1)\n",
        "category_encoded = encoder.fit_transform(categories)\n",
        "\n",
        "features = np.array([[p['rating'], p['rating_count']] for p in products_dict.values()])\n",
        "features = np.concatenate((category_encoded, features), axis=1)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "row_indices = scaler.fit_transform(features)\n",
        "\n",
        "# Calculate column indices using Word2Vec embeddings for better semantic similarity\n",
        "corpus = [p['about_product'].split() for p in products_dict.values()]\n",
        "word2vec_model = Word2Vec(sentences=corpus, vector_size=50, window=5, min_count=1, workers=4)\n",
        "product_vectors = np.array([np.mean([word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
        "                                    or [np.zeros(50)], axis=0) for words in corpus])\n",
        "\n",
        "column_indices = scaler.fit_transform(product_vectors)\n",
        "\n",
        "# Normalize indices to fit within grid size\n",
        "normalized_row_indices = row_indices[:, 0]\n",
        "normalized_col_indices = column_indices[:, 0]\n",
        "row_indices = (normalized_row_indices * (grid_size - 1)).astype(int)\n",
        "column_indices = (normalized_col_indices * (grid_size - 1)).astype(int)\n",
        "\n",
        "# Shuffle the product IDs to ensure a random distribution\n",
        "product_ids = list(products_dict.keys())\n",
        "random.shuffle(product_ids)\n",
        "\n",
        "# Place products in the grid based on normalized indices\n",
        "for idx, product_id in enumerate(product_ids):\n",
        "    row = row_indices[idx]\n",
        "    col = column_indices[idx]\n",
        "    while grid[row, col] is not None:\n",
        "        col = (col + 1) % grid_size\n",
        "        if col == 0:\n",
        "            row = (row + 1) % grid_size\n",
        "    grid[row, col] = product_id\n",
        "    print(f\"Product ID: {product_id}, Normalized Row: {normalized_row_indices[idx]:.2f}, Normalized Column: {normalized_col_indices[idx]:.2f}\")\n",
        "\n",
        "# A* search functions\n",
        "def calculate_similarity(product1, product2):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    text_vectors = vectorizer.fit_transform([product1['about_product'], product2['about_product']])\n",
        "    cosine_sim = cosine_similarity(text_vectors[0:1], text_vectors[1:2])[0][0]\n",
        "    rating_similarity = min(product1['rating'], product2['rating']) / max(product1['rating'], product2['rating'])\n",
        "    rating_count_similarity = min(product1['rating_count'], product2['rating_count']) / max(product1['rating_count'], product2['rating_count'])\n",
        "    similarity_score = cosine_sim + rating_similarity + rating_count_similarity\n",
        "    return similarity_score\n",
        "\n",
        "def a_star_search_recommendations(start, grid, products_dict, max_recommendations=10):\n",
        "    def heuristic(product1, product2):\n",
        "        return calculate_similarity(products_dict[product1], products_dict[product2])\n",
        "\n",
        "    def get_neighbors(row, col):\n",
        "        neighbors = []\n",
        "        if row > 0: neighbors.append((row - 1, col))\n",
        "        if row < grid_size - 1: neighbors.append((row + 1, col))\n",
        "        if col > 0: neighbors.append((row, col - 1))\n",
        "        if col < grid_size - 1: neighbors.append((row, col + 1))\n",
        "        return neighbors\n",
        "\n",
        "    start_position = None\n",
        "    for i in range(grid_size):\n",
        "        for j in range(grid_size):\n",
        "            if grid[i, j] == start:\n",
        "                start_position = (i, j)\n",
        "                break\n",
        "        if start_position:\n",
        "            break\n",
        "\n",
        "    open_set = []\n",
        "    heappush(open_set, (0, start_position))\n",
        "    came_from = {}\n",
        "    g_score = {pos: float('inf') for row in range(grid_size) for pos in [(row, col) for col in range(grid_size)]}\n",
        "    g_score[start_position] = 0\n",
        "    f_score = {pos: float('inf') for row in range(grid_size) for pos in [(row, col) for col in range(grid_size)]}\n",
        "    f_score[start_position] = 0\n",
        "\n",
        "    recommendations = []\n",
        "    path = []\n",
        "    while open_set and len(recommendations) < max_recommendations:\n",
        "        _, current = heappop(open_set)\n",
        "        path.append(current)\n",
        "        current_product = grid[current[0], current[1]]\n",
        "        if current_product not in recommendations:\n",
        "            recommendations.append(current_product)\n",
        "        neighbors = get_neighbors(current[0], current[1])\n",
        "        for neighbor in neighbors:\n",
        "            neighbor_product = grid[neighbor[0], neighbor[1]]\n",
        "            if neighbor_product:\n",
        "                tentative_g_score = g_score[current] + calculate_similarity(products_dict[current_product], products_dict[neighbor_product])\n",
        "                if tentative_g_score < g_score[neighbor]:\n",
        "                    came_from[neighbor] = current\n",
        "                    g_score[neighbor] = tentative_g_score\n",
        "                    f_score[neighbor] = g_score[neighbor] + heuristic(current_product, neighbor_product)\n",
        "                    heappush(open_set, (f_score[neighbor], neighbor))\n",
        "\n",
        "    return recommendations, path\n",
        "\n",
        "# Choose a valid start product ID from the printed list\n",
        "start_product_id = \"B07VLDQMV3\"  # Use the first available product ID\n",
        "recommendations, path = a_star_search_recommendations(start_product_id, grid, products_dict, max_recommendations=10)\n",
        "print(\"Recommended products:\", recommendations)\n",
        "\n",
        "# Visualization with A* path\n",
        "plt.figure(figsize=(50, 50))\n",
        "plt.imshow(np.full((grid_size, grid_size), np.nan), cmap='viridis', interpolation='none')  # Empty grid\n",
        "plt.title('Product Grid Based on Hybrid Filtering and Embeddings')\n",
        "\n",
        "# Define colors for categories\n",
        "categories_unique = list(set(p['category'] for p in products_dict.values()))\n",
        "category_colors = {category: plt.cm.tab20(i / len(categories_unique)) for i, category in enumerate(categories_unique)}\n",
        "\n",
        "for i in range(grid_size):\n",
        "    plt.axhline(i - 0.5, color='gray', linewidth=0.5)\n",
        "    plt.axvline(i - 0.5, color='gray', linewidth=0.5)\n",
        "\n",
        "for (row, col), product_id in np.ndenumerate(grid):\n",
        "    if product_id is not None:\n",
        "        product = products_dict[product_id]\n",
        "        color = category_colors[product['category']]\n",
        "        plt.text(col, row, product_id, ha='center', va='center', fontsize=8, bbox=dict(facecolor=color, edgecolor='black', boxstyle='round,pad=0.3'))\n",
        "\n",
        "# Highlight the A* path\n",
        "for (row, col) in path:\n",
        "    plt.plot(col, row, 'ro')  # Mark the path with red dots\n",
        "\n",
        "# Highlight the recommended products\n",
        "for product_id in recommendations:\n",
        "    for i in range(grid_size):\n",
        "        for j in range(grid_size):\n",
        "            if grid[i, j] == product_id:\n",
        "                plt.text(j, i, product_id, ha='center', va='center', fontsize=8, bbox=dict(facecolor='yellow', edgecolor='black', boxstyle='round,pad=0.3'))\n",
        "\n",
        "# Create a legend with category colors\n",
        "handles = [mpatches.Patch(color=color, label=category) for category, color in category_colors.items()]\n",
        "plt.legend(handles=handles, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
        "\n",
        "plt.xlabel('Embedding-based Column Index')\n",
        "plt.ylabel('Hybrid Filtering-based Row Index')\n",
        "plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yN0PzQtj8HB",
        "outputId": "63deb399-6cb9-42d1-8a34-22d4cfd4dce9"
      },
      "outputs": [],
      "source": [
        "# Print recommended product details\n",
        "print(\"Recommended products:\")\n",
        "for product_id in recommendations:\n",
        "    product = products_dict[product_id]\n",
        "    print(f\"Product ID: {product['product_id']}\")\n",
        "    print(f\"Product Name: {product['product_name']}  \")\n",
        "    print(f\"Category: {product['category']}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzccoqHslIhT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1ALn0polItF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTY3HYiElI1J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXOmTp03lI_j",
        "outputId": "c8e5eb54-e49a-47e6-b22e-67d49a21e577"
      },
      "outputs": [],
      "source": [
        "# ********************** changing the color completely **************************\n",
        "import csv\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models import Word2Vec\n",
        "import random\n",
        "import matplotlib.patches as mpatches\n",
        "from heapq import heappush, heappop\n",
        "\n",
        "# Create a OneHotEncoder instance\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "csv_file = \"amazon.csv\"\n",
        "\n",
        "# Read the CSV data and create a dictionary of products\n",
        "products_dict = {}\n",
        "with open(csv_file, mode='r', encoding='utf-8') as file:\n",
        "    csv_reader = csv.DictReader(file)\n",
        "    for row in csv_reader:\n",
        "        # Extract and clean the rating_count\n",
        "        try:\n",
        "            rating_count = int(row['rating_count'].replace(',', '')) if row['rating_count'] else 0\n",
        "        except ValueError:\n",
        "            rating_count = 0\n",
        "\n",
        "        # Extract and clean the rating\n",
        "        try:\n",
        "            rating = float(row['rating'])\n",
        "        except ValueError:\n",
        "            rating = 0.0\n",
        "\n",
        "        # Create a dictionary for each product\n",
        "        product_details = {\n",
        "            'product_id': row['product_id'],\n",
        "            'product_name': row['product_name'],\n",
        "            'category': row['category'],\n",
        "            'rating': rating,\n",
        "            'rating_count': rating_count,\n",
        "            'about_product': row['about_product']\n",
        "        }\n",
        "        # Use product_id as the key for the products dictionary\n",
        "        products_dict[row['product_id']] = product_details\n",
        "\n",
        "# Print available product IDs\n",
        "print(\"Available product IDs:\", list(products_dict.keys())[:10])  # Print first 10 product IDs for checking\n",
        "\n",
        "# Construct the grid\n",
        "num_products = len(products_dict)\n",
        "grid_size = int(np.ceil(np.sqrt(num_products)))\n",
        "grid = np.empty((grid_size, grid_size), dtype=object)\n",
        "\n",
        "# Calculate row indices using hybrid filtering\n",
        "categories = np.array([p['category'] for p in products_dict.values()]).reshape(-1, 1)\n",
        "category_encoded = encoder.fit_transform(categories)\n",
        "\n",
        "features = np.array([[p['rating'], p['rating_count']] for p in products_dict.values()])\n",
        "features = np.concatenate((category_encoded, features), axis=1)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "row_indices = scaler.fit_transform(features)\n",
        "\n",
        "# Calculate column indices using Word2Vec embeddings for better semantic similarity\n",
        "corpus = [p['about_product'].split() for p in products_dict.values()]\n",
        "word2vec_model = Word2Vec(sentences=corpus, vector_size=50, window=5, min_count=1, workers=4)\n",
        "product_vectors = np.array([np.mean([word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
        "                                    or [np.zeros(50)], axis=0) for words in corpus])\n",
        "\n",
        "column_indices = scaler.fit_transform(product_vectors)\n",
        "\n",
        "# Normalize indices to fit within grid size\n",
        "normalized_row_indices = row_indices[:, 0]\n",
        "normalized_col_indices = column_indices[:, 0]\n",
        "row_indices = (normalized_row_indices * (grid_size - 1)).astype(int)\n",
        "column_indices = (normalized_col_indices * (grid_size - 1)).astype(int)\n",
        "\n",
        "# Shuffle the product IDs to ensure a random distribution\n",
        "product_ids = list(products_dict.keys())\n",
        "random.shuffle(product_ids)\n",
        "\n",
        "# Place products in the grid based on normalized indices\n",
        "for idx, product_id in enumerate(product_ids):\n",
        "    row = row_indices[idx]\n",
        "    col = column_indices[idx]\n",
        "    while grid[row, col] is not None:\n",
        "        col = (col + 1) % grid_size\n",
        "        if col == 0:\n",
        "            row = (row + 1) % grid_size\n",
        "    grid[row, col] = product_id\n",
        "\n",
        "# A* search functions\n",
        "def calculate_similarity(product1, product2):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    text_vectors = vectorizer.fit_transform([product1['about_product'], product2['about_product']])\n",
        "    cosine_sim = cosine_similarity(text_vectors[0:1], text_vectors[1:2])[0][0]\n",
        "    rating_similarity = min(product1['rating'], product2['rating']) / max(product1['rating'], product2['rating'])\n",
        "    rating_count_similarity = min(product1['rating_count'], product2['rating_count']) / max(product1['rating_count'], product2['rating_count'])\n",
        "    similarity_score = cosine_sim + rating_similarity + rating_count_similarity\n",
        "    return similarity_score\n",
        "\n",
        "def a_star_search_recommendations(start, grid, products_dict, max_recommendations=10):\n",
        "    def heuristic(product_id):\n",
        "        current_product = products_dict[product_id]\n",
        "        avg_similarity = np.mean([calculate_similarity(current_product, products_dict[other_id])\n",
        "                                  for other_id in products_dict if other_id != product_id])\n",
        "        return avg_similarity\n",
        "\n",
        "    def get_neighbors(row, col):\n",
        "        neighbors = []\n",
        "        if row > 0 and grid[row - 1, col] is not None: neighbors.append((row - 1, col))\n",
        "        if row < grid_size - 1 and grid[row + 1, col] is not None: neighbors.append((row + 1, col))\n",
        "        if col > 0 and grid[row, col - 1] is not None: neighbors.append((row, col - 1))\n",
        "        if col < grid_size - 1 and grid[row, col + 1] is not None: neighbors.append((row, col + 1))\n",
        "        return neighbors\n",
        "\n",
        "    start_position = None\n",
        "    for i in range(grid_size):\n",
        "        for j in range(grid_size):\n",
        "            if grid[i, j] == start:\n",
        "                start_position = (i, j)\n",
        "                break\n",
        "        if start_position:\n",
        "            break\n",
        "\n",
        "    if start_position is None:\n",
        "        raise ValueError(\"Start product ID not found in the grid.\")\n",
        "\n",
        "    open_set = []\n",
        "    heappush(open_set, (0, start_position))\n",
        "    came_from = {}\n",
        "    g_score = {pos: float('inf') for row in range(grid_size) for pos in [(row, col) for col in range(grid_size)]}\n",
        "    g_score[start_position] = 0\n",
        "    f_score = {pos: float('inf') for row in range(grid_size) for pos in [(row, col) for col in range(grid_size)]}\n",
        "    f_score[start_position] = heuristic(start)\n",
        "\n",
        "    recommendations = []\n",
        "    path = []\n",
        "    while open_set and len(recommendations) < max_recommendations:\n",
        "        _, current = heappop(open_set)\n",
        "        path.append(current)\n",
        "        current_product = grid[current[0], current[1]]\n",
        "        if current_product not in recommendations:\n",
        "            recommendations.append(current_product)\n",
        "        neighbors = get_neighbors(current[0], current[1])\n",
        "        for neighbor in neighbors:\n",
        "            neighbor_product = grid[neighbor[0], neighbor[1]]\n",
        "            if neighbor_product:\n",
        "                tentative_g_score = g_score[current] + calculate_similarity(products_dict[current_product], products_dict[neighbor_product])\n",
        "                if tentative_g_score < g_score[neighbor]:\n",
        "                    came_from[neighbor] = current\n",
        "                    g_score[neighbor] = tentative_g_score\n",
        "                    f_score[neighbor] = g_score[neighbor] + heuristic(neighbor_product)\n",
        "                    heappush(open_set, (f_score[neighbor], neighbor))\n",
        "\n",
        "    return recommendations, path\n",
        "\n",
        "# Choose a valid start product ID from the printed list\n",
        "start_product_id = \"B00IN9AGAE\"  # Use the first available product ID\n",
        "recommendations, path = a_star_search_recommendations(start_product_id, grid, products_dict, max_recommendations=10)\n",
        "print(\"Recommended products:\", recommendations)\n",
        "\n",
        "# Visualization with A* path\n",
        "plt.figure(figsize=(20, 20))\n",
        "plt.imshow(np.full((grid_size, grid_size), np.nan), cmap='viridis', interpolation='none')  # Empty grid\n",
        "plt.title('Product Grid Based on Hybrid Filtering and Embeddings')\n",
        "\n",
        "# Define colors for categories\n",
        "categories_unique = list(set(p['category'] for p in products_dict.values()))\n",
        "category_colors = {category: plt.cm.tab20(i / len(categories_unique)) for i, category in enumerate(categories_unique)}\n",
        "\n",
        "for i in range(grid_size):\n",
        "    plt.axhline(i - 0.5, color='gray', linewidth=0.5)\n",
        "    plt.axvline(i - 0.5, color='gray', linewidth=0.5)\n",
        "\n",
        "for (row, col), product_id in np.ndenumerate(grid):\n",
        "    if product_id is not None:\n",
        "        product = products_dict[product_id]\n",
        "        color = category_colors[product['category']]\n",
        "        plt.gca().add_patch(plt.Rectangle((col - 0.5, row - 0.5), 1, 1, edgecolor='black', facecolor=color, lw=1))\n",
        "        plt.text(col, row, product_id, ha='center', va='center', fontsize=8, color='black')\n",
        "\n",
        "# Highlight the recommended products with a distinct color\n",
        "recommendation_color = 'red'\n",
        "for (row, col) in path:\n",
        "    if grid[row, col] in recommendations:\n",
        "        plt.gca().add_patch(plt.Rectangle((col - 0.5, row - 0.5), 1, 1, edgecolor='red', facecolor=recommendation_color, lw=2))\n",
        "\n",
        "# Create a legend for the categories\n",
        "handles = [mpatches.Patch(color=color, label=category) for category, color in category_colors.items()]\n",
        "handles.append(mpatches.Patch(color=recommendation_color, label='Recommended Products'))\n",
        "plt.legend(handles=handles, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models import Word2Vec\n",
        "import random\n",
        "import matplotlib.patches as mpatches\n",
        "from heapq import heappush, heappop\n",
        "\n",
        "# Create a OneHotEncoder instance\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "csv_file = \"amazon_reviews.csv\"\n",
        "\n",
        "# Read the CSV data and create a dictionary of products\n",
        "products_dict = {}\n",
        "with open(csv_file, mode='r', encoding='utf-8') as file:\n",
        "    csv_reader = csv.DictReader(file)\n",
        "    for row in csv_reader:\n",
        "        # Extract and clean the rating_number\n",
        "        try:\n",
        "            rating_number = int(row['rating_number'].replace(',', '')) if row['rating_number'] else 0\n",
        "        except ValueError:\n",
        "            rating_number = 0\n",
        "\n",
        "        # Extract and clean the average_rating\n",
        "        try:\n",
        "            average_rating = float(row['average_rating'])\n",
        "        except ValueError:\n",
        "            average_rating = 0.0\n",
        "\n",
        "        # Create a dictionary for each product\n",
        "        product_details = {\n",
        "            'product_id': row['parent_asin'],  # Assuming parent_asin is the unique product identifier\n",
        "            'product_name': row['title'],\n",
        "            'category': row['main_category'],\n",
        "            'rating': average_rating,\n",
        "            'rating_count': rating_number,\n",
        "            'about_product': row['description'],\n",
        "            'bought_together': row['bought_together']\n",
        "        }\n",
        "        # Use parent_asin as the key for the products dictionary\n",
        "        products_dict[row['parent_asin']] = product_details\n",
        "\n",
        "# Print available product IDs\n",
        "print(\"Available product IDs:\", list(products_dict.keys())[:10])  # Print first 10 product IDs for checking\n",
        "\n",
        "# Construct the grid\n",
        "num_products = len(products_dict)\n",
        "grid_size = int(np.ceil(np.sqrt(num_products)))\n",
        "grid = np.empty((grid_size, grid_size), dtype=object)\n",
        "\n",
        "# Calculate row indices using hybrid filtering\n",
        "categories = np.array([p['category'] for p in products_dict.values()]).reshape(-1, 1)\n",
        "category_encoded = encoder.fit_transform(categories)\n",
        "\n",
        "features = np.array([[p['rating'], p['rating_count']] for p in products_dict.values()])\n",
        "features = np.concatenate((category_encoded, features), axis=1)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "row_indices = scaler.fit_transform(features)\n",
        "\n",
        "# Calculate column indices using Word2Vec embeddings for better semantic similarity\n",
        "corpus = [p['about_product'].split() for p in products_dict.values()]\n",
        "word2vec_model = Word2Vec(sentences=corpus, vector_size=50, window=5, min_count=1, workers=4)\n",
        "product_vectors = np.array([np.mean([word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
        "                                    or [np.zeros(50)], axis=0) for words in corpus])\n",
        "\n",
        "column_indices = scaler.fit_transform(product_vectors)\n",
        "\n",
        "# Normalize indices to fit within grid size\n",
        "normalized_row_indices = row_indices[:, 0]\n",
        "normalized_col_indices = column_indices[:, 0]\n",
        "row_indices = (normalized_row_indices * (grid_size - 1)).astype(int)\n",
        "column_indices = (normalized_col_indices * (grid_size - 1)).astype(int)\n",
        "\n",
        "# Shuffle the product IDs to ensure a random distribution\n",
        "product_ids = list(products_dict.keys())\n",
        "random.shuffle(product_ids)\n",
        "\n",
        "# Place products in the grid based on normalized indices\n",
        "for idx, product_id in enumerate(product_ids):\n",
        "    row = row_indices[idx]\n",
        "    col = column_indices[idx]\n",
        "    while grid[row, col] is not None:\n",
        "        col = (col + 1) % grid_size\n",
        "        if col == 0:\n",
        "            row = (row + 1) % grid_size\n",
        "    grid[row, col] = product_id\n",
        "    print(f\"Product ID: {product_id}, Normalized Row: {normalized_row_indices[idx]:.2f}, Normalized Column: {normalized_col_indices[idx]:.2f}\")\n",
        "\n",
        "# A* search functions\n",
        "def calculate_similarity(product1, product2):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    text_vectors = vectorizer.fit_transform([product1['about_product'], product2['about_product']])\n",
        "    cosine_sim = cosine_similarity(text_vectors[0:1], text_vectors[1:2])[0][0]\n",
        "    \n",
        "    if product1['rating'] == 0 or product2['rating'] == 0:\n",
        "        rating_similarity = 0\n",
        "    else:\n",
        "        rating_similarity = min(product1['rating'], product2['rating']) / max(product1['rating'], product2['rating'])\n",
        "    \n",
        "    if product1['rating_count'] == 0 or product2['rating_count'] == 0:\n",
        "        rating_count_similarity = 0\n",
        "    else:\n",
        "        rating_count_similarity = min(product1['rating_count'], product2['rating_count']) / max(product1['rating_count'], product2['rating_count'])\n",
        "    \n",
        "    similarity_score = cosine_sim + rating_similarity + rating_count_similarity\n",
        "    return similarity_score\n",
        "\n",
        "def a_star_search_recommendations(start, grid, products_dict, max_recommendations=10):\n",
        "    def heuristic(product1, product2):\n",
        "        return calculate_similarity(products_dict[product1], products_dict[product2])\n",
        "\n",
        "    def get_neighbors(row, col):\n",
        "        neighbors = []\n",
        "        if row > 0: neighbors.append((row - 1, col))\n",
        "        if row < grid_size - 1: neighbors.append((row + 1, col))\n",
        "        if col > 0: neighbors.append((row, col - 1))\n",
        "        if col < grid_size - 1: neighbors.append((row, col + 1))\n",
        "        return neighbors\n",
        "\n",
        "    start_position = None\n",
        "    for i in range(grid_size):\n",
        "        for j in range(grid_size):\n",
        "            if grid[i, j] == start:\n",
        "                start_position = (i, j)\n",
        "                break\n",
        "        if start_position:\n",
        "            break\n",
        "\n",
        "    open_set = []\n",
        "    heappush(open_set, (0, start_position))\n",
        "    came_from = {}\n",
        "    g_score = {pos: float('inf') for row in range(grid_size) for pos in [(row, col) for col in range(grid_size)]}\n",
        "    g_score[start_position] = 0\n",
        "    f_score = {pos: float('inf') for row in range(grid_size) for pos in [(row, col) for col in range(grid_size)]}\n",
        "    f_score[start_position] = 0\n",
        "\n",
        "    recommendations = []\n",
        "    path = []\n",
        "    while open_set and len(recommendations) < max_recommendations:\n",
        "        _, current = heappop(open_set)\n",
        "        path.append(current)\n",
        "        current_product = grid[current[0], current[1]]\n",
        "        if current_product not in recommendations:\n",
        "            recommendations.append(current_product)\n",
        "        neighbors = get_neighbors(current[0], current[1])\n",
        "        for neighbor in neighbors:\n",
        "            neighbor_product = grid[neighbor[0], neighbor[1]]\n",
        "            if neighbor_product:\n",
        "                tentative_g_score = g_score[current] + calculate_similarity(products_dict[current_product], products_dict[neighbor_product])\n",
        "                if tentative_g_score < g_score[neighbor]:\n",
        "                    came_from[neighbor] = current\n",
        "                    g_score[neighbor] = tentative_g_score\n",
        "                    f_score[neighbor] = g_score[neighbor] + heuristic(current_product, neighbor_product)\n",
        "                    heappush(open_set, (f_score[neighbor], neighbor))\n",
        "\n",
        "    return recommendations, path\n",
        "\n",
        "# Choose a valid start product ID from the printed list\n",
        "start_product_id = \"B00KAS9ZMG\"  # Use the first available product ID\n",
        "recommendations, path = a_star_search_recommendations(start_product_id, grid, products_dict, max_recommendations=10)\n",
        "print(\"Recommended products:\", recommendations)\n",
        "\n",
        "# Visualization with A* path\n",
        "plt.figure(figsize=(50, 50))\n",
        "plt.imshow(np.full((grid_size, grid_size), np.nan), cmap='viridis', interpolation='none')  # Empty grid\n",
        "plt.title('Product Grid Based on Hybrid Filtering and Embeddings')\n",
        "\n",
        "# Define colors for categories\n",
        "categories_unique = list(set(p['category'] for p in products_dict.values()))\n",
        "category_colors = {category: plt.cm.tab20(i / len(categories_unique)) for i, category in enumerate(categories_unique)}\n",
        "\n",
        "for i in range(grid_size):\n",
        "    plt.axhline(i - 0.5, color='gray', linewidth=0.5)\n",
        "    plt.axvline(i - 0.5, color='gray', linewidth=0.5)\n",
        "\n",
        "for (row, col), product_id in np.ndenumerate(grid):\n",
        "    if product_id is not None:\n",
        "        product = products_dict[product_id]\n",
        "        color = category_colors[product['category']]\n",
        "        plt.text(col, row, product_id, ha='center', va='center', fontsize=8, bbox=dict(facecolor=color, edgecolor='black', boxstyle='round,pad=0.3'))\n",
        "\n",
        "# Highlight the A* path\n",
        "for (row, col) in path:\n",
        "    plt.plot(col, row, 'ro')  # Mark the path with red dots\n",
        "\n",
        "# Highlight the recommended products\n",
        "for product_id in recommendations:\n",
        "    for i in range(grid_size):\n",
        "        for j in range(grid_size):\n",
        "            if grid[i, j] == product_id:\n",
        "                plt.text(j, i, product_id, ha='center', va='center', fontsize=8, bbox=dict(facecolor='yellow', edgecolor='black', boxstyle='round,pad=0.3'))\n",
        "\n",
        "# Create a legend with category colors\n",
        "handles = [mpatches.Patch(color=color, label=category) for category, color in category_colors.items()]\n",
        "plt.legend(handles=handles, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
        "\n",
        "plt.xlabel('Embedding-based Column Index')\n",
        "plt.ylabel('Hybrid Filtering-based Row Index')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print recommended product details\n",
        "print(\"Recommended products:\")\n",
        "for product_id in recommendations:\n",
        "    product = products_dict[product_id]\n",
        "    print(f\"Product ID: {product['product_id']}\")\n",
        "    print(f\"Product Name: {product['product_name']}  \")\n",
        "    print(f\"Category: {product['category']}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models import Word2Vec\n",
        "import random\n",
        "import matplotlib.patches as mpatches\n",
        "from heapq import heappush, heappop\n",
        "\n",
        "# Create a OneHotEncoder instance\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "csv_file = \"amazon_reviews.csv\"\n",
        "\n",
        "# Read the CSV data and create a dictionary of products\n",
        "products_dict = {}\n",
        "with open(csv_file, mode='r', encoding='utf-8') as file:\n",
        "    csv_reader = csv.DictReader(file)\n",
        "    for row in csv_reader:\n",
        "        # Extract and clean the rating_number\n",
        "        try:\n",
        "            rating_number = int(row['rating_number'].replace(',', '')) if row['rating_number'] else 0\n",
        "        except ValueError:\n",
        "            rating_number = 0\n",
        "\n",
        "        # Extract and clean the average_rating\n",
        "        try:\n",
        "            average_rating = float(row['average_rating'])\n",
        "        except ValueError:\n",
        "            average_rating = 0.0\n",
        "\n",
        "        # Create a dictionary for each product\n",
        "        product_details = {\n",
        "            'product_id': row['parent_asin'],  # Assuming parent_asin is the unique product identifier\n",
        "            'product_name': row['title'],\n",
        "            'category': row['main_category'],\n",
        "            'rating': average_rating,\n",
        "            'rating_count': rating_number,\n",
        "            'about_product': row['description'],\n",
        "            'bought_together': row['bought_together']\n",
        "        }\n",
        "        # Use parent_asin as the key for the products dictionary\n",
        "        products_dict[row['parent_asin']] = product_details\n",
        "\n",
        "# Print available product IDs\n",
        "print(\"Available product IDs:\", list(products_dict.keys())[:10])  # Print first 10 product IDs for checking\n",
        "\n",
        "# Construct the grid\n",
        "num_products = len(products_dict)\n",
        "grid_size = int(np.ceil(np.sqrt(num_products)))\n",
        "grid = np.empty((grid_size, grid_size), dtype=object)\n",
        "\n",
        "# Calculate row indices using hybrid filtering\n",
        "categories = np.array([p['category'] for p in products_dict.values()]).reshape(-1, 1)\n",
        "category_encoded = encoder.fit_transform(categories)\n",
        "\n",
        "features = np.array([[p['rating'],np.log1p['rating_count']] for p in products_dict.values()])\n",
        "features = np.concatenate((category_encoded, features), axis=1)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "row_indices = scaler.fit_transform(features)\n",
        "\n",
        "# Calculate column indices using Word2Vec embeddings for better semantic similarity\n",
        "corpus = [p['about_product'].split() for p in products_dict.values()]\n",
        "word2vec_model = Word2Vec(sentences=corpus, vector_size=50, window=5, min_count=1, workers=4)\n",
        "product_vectors = np.array([np.mean([word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
        "                                    or [np.zeros(50)], axis=0) for words in corpus])\n",
        "\n",
        "column_indices = scaler.fit_transform(product_vectors)\n",
        "\n",
        "# Normalize indices to fit within grid size\n",
        "normalized_row_indices = row_indices[:, 0]\n",
        "normalized_col_indices = column_indices[:, 0]\n",
        "row_indices = (normalized_row_indices * (grid_size - 1)).astype(int)\n",
        "column_indices = (normalized_col_indices * (grid_size - 1)).astype(int)\n",
        "\n",
        "# Sort products by category to place similar categories together\n",
        "sorted_product_ids = sorted(products_dict.keys(), key=lambda x: products_dict[x]['category'])\n",
        "\n",
        "# Place products in the grid based on normalized indices\n",
        "for idx, product_id in enumerate(sorted_product_ids):\n",
        "    row = row_indices[idx]\n",
        "    col = column_indices[idx]\n",
        "    while grid[row, col] is not None:\n",
        "        col = (col + 1) % grid_size\n",
        "        if col == 0:\n",
        "            row = (row + 1) % grid_size\n",
        "    grid[row, col] = product_id\n",
        "    print(f\"Product ID: {product_id}, Normalized Row: {normalized_row_indices[idx]:.2f}, Normalized Column: {normalized_col_indices[idx]:.2f}\")\n",
        "\n",
        "# A* search functions\n",
        "def calculate_similarity(product1, product2):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    text_vectors = vectorizer.fit_transform([product1['about_product'], product2['about_product']])\n",
        "    cosine_sim = cosine_similarity(text_vectors[0:1], text_vectors[1:2])[0][0]\n",
        "    \n",
        "    if product1['rating'] == 0 or product2['rating'] == 0:\n",
        "        rating_similarity = 0\n",
        "    else:\n",
        "        rating_similarity = min(product1['rating'], product2['rating']) / max(product1['rating'], product2['rating'])\n",
        "    \n",
        "    if product1['rating_count'] == 0 or product2['rating_count'] == 0:\n",
        "        rating_count_similarity = 0\n",
        "    else:\n",
        "        rating_count_similarity = min(product1['rating_count'], product2['rating_count']) / max(product1['rating_count'], product2['rating_count'])\n",
        "    \n",
        "    similarity_score = cosine_sim + rating_similarity + rating_count_similarity\n",
        "    return similarity_score\n",
        "\n",
        "def a_star_search_recommendations(start, grid, products_dict, max_recommendations=10):\n",
        "    def heuristic(product1, product2):\n",
        "        grid_distance = abs(product1[0] - product2[0]) + abs(product1[1] - product2[1])\n",
        "        product_similarity = calculate_similarity(products_dict[grid[product1[0], product1[1]]], products_dict[grid[product2[0], product2[1]]])\n",
        "        return grid_distance - product_similarity\n",
        "\n",
        "    def get_neighbors(row, col):\n",
        "        neighbors = []\n",
        "        if row > 0: neighbors.append((row - 1, col))\n",
        "        if row < grid_size - 1: neighbors.append((row + 1, col))\n",
        "        if col > 0: neighbors.append((row, col - 1))\n",
        "        if col < grid_size - 1: neighbors.append((row, col + 1))\n",
        "        return neighbors\n",
        "\n",
        "    start_position = None\n",
        "    for i in range(grid_size):\n",
        "        for j in range(grid_size):\n",
        "            if grid[i, j] == start:\n",
        "                start_position = (i, j)\n",
        "                break\n",
        "        if start_position:\n",
        "            break\n",
        "\n",
        "    open_set = []\n",
        "    heappush(open_set, (0, start_position))\n",
        "    came_from = {}\n",
        "    g_score = {pos: float('inf') for row in range(grid_size) for pos in [(row, col) for col in range(grid_size)]}\n",
        "    g_score[start_position] = 0\n",
        "    f_score = {pos: float('inf') for row in range(grid_size) for pos in [(row, col) for col in range(grid_size)]}\n",
        "    f_score[start_position] = 0\n",
        "\n",
        "    recommendations = []\n",
        "    path = []\n",
        "    while open_set and len(recommendations) < max_recommendations:\n",
        "        _, current = heappop(open_set)\n",
        "        path.append(current)\n",
        "        current_product = grid[current[0], current[1]]\n",
        "        if current_product not in recommendations:\n",
        "            recommendations.append(current_product)\n",
        "        neighbors = get_neighbors(current[0], current[1])\n",
        "        for neighbor in neighbors:\n",
        "            neighbor_product = grid[neighbor[0], neighbor[1]]\n",
        "            if neighbor_product:\n",
        "                tentative_g_score = g_score[current] + calculate_similarity(products_dict[current_product], products_dict[neighbor_product])\n",
        "                if tentative_g_score < g_score[neighbor]:\n",
        "                    came_from[neighbor] = current\n",
        "                    g_score[neighbor] = tentative_g_score\n",
        "                    f_score[neighbor] = g_score[neighbor] + heuristic(current, neighbor)\n",
        "                    heappush(open_set, (f_score[neighbor], neighbor))\n",
        "\n",
        "    return recommendations, path\n",
        "\n",
        "# Choose a valid start product ID from the printed list\n",
        "start_product_id =\"B094C5ZN1M\"\n",
        "#\"B017086GMK\" # Use the first available product ID\n",
        "recommendations, path = a_star_search_recommendations(start_product_id, grid, products_dict, max_recommendations=10)\n",
        "print(\"Recommended products:\", recommendations)\n",
        "\n",
        "# Visualization with A* path\n",
        "plt.figure(figsize=(50, 50))\n",
        "plt.imshow(np.full((grid_size, grid_size), np.nan), cmap='viridis', interpolation='none')  # Empty grid\n",
        "plt.title('Product Grid Based on Hybrid Filtering and Embeddings')\n",
        "\n",
        "# Define colors for categories\n",
        "categories_unique = list(set(p['category'] for p in products_dict.values()))\n",
        "category_colors = {category: plt.cm.tab20(i / len(categories_unique)) for i, category in enumerate(categories_unique)}\n",
        "\n",
        "for i in range(grid_size):\n",
        "    plt.axhline(i - 0.5, color='gray', linewidth=0.5)\n",
        "    plt.axvline(i - 0.5, color='gray', linewidth=0.5)\n",
        "\n",
        "for (row, col), product_id in np.ndenumerate(grid):\n",
        "    if product_id is not None:\n",
        "        product = products_dict[product_id]\n",
        "        color = category_colors[product['category']]\n",
        "        plt.text(col, row, product_id, ha='center', va='center', fontsize=8, bbox=dict(facecolor=color, edgecolor='black', boxstyle='round,pad=0.3'))\n",
        "\n",
        "# Highlight the A* path\n",
        "for (row, col) in path:\n",
        "    plt.plot(col, row, 'ro')  # Mark the path with red dots\n",
        "\n",
        "# Highlight the recommended products\n",
        "for product_id in recommendations:\n",
        "    for i in range(grid_size):\n",
        "        for j in range(grid_size):\n",
        "            if grid[i, j] == product_id:\n",
        "                plt.text(j, i, product_id, ha='center', va='center', fontsize=8, bbox=dict(facecolor='yellow', edgecolor='black', boxstyle='round,pad=0.3'))\n",
        "\n",
        "# Create a legend with category colors\n",
        "handles = [mpatches.Patch(color=color, label=category) for category, color in category_colors.items()]\n",
        "plt.legend(handles=handles, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
        "\n",
        "plt.xlabel('Embedding-based Column Index')\n",
        "plt.ylabel('Hybrid Filtering-based Row Index')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print recommended product details\n",
        "print(\"Recommended products:\")\n",
        "for product_id in recommendations:\n",
        "    product = products_dict[product_id]\n",
        "    print(f\"Product ID: {product['product_id']}\")\n",
        "    print(f\"Product Name: {product['product_name']}  \")\n",
        "    print(f\"Category: {product['category']}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization with A* path\n",
        "plt.figure(figsize=(100, 100))\n",
        "plt.imshow(np.full((grid_size, grid_size), np.nan), cmap='viridis', interpolation='none')  # Empty grid\n",
        "plt.title('Product Grid Based on Hybrid Filtering and Embeddings')\n",
        "\n",
        "# Define colors for categories\n",
        "categories_unique = list(set(p['category'] for p in products_dict.values()))\n",
        "category_colors = {category: plt.cm.tab20(i / len(categories_unique)) for i, category in enumerate(categories_unique)}\n",
        "\n",
        "for i in range(grid_size):\n",
        "    plt.axhline(i - 0.5, color='gray', linewidth=0.5)\n",
        "    plt.axvline(i - 0.5, color='gray', linewidth=0.5)\n",
        "\n",
        "for (row, col), product_id in np.ndenumerate(grid):\n",
        "    if product_id is not None:\n",
        "        product = products_dict[product_id]\n",
        "        color = category_colors[product['category']]\n",
        "        plt.text(col, row, product_id, ha='center', va='center', fontsize=8, bbox=dict(facecolor=color, edgecolor='black', boxstyle='round,pad=0.3'))\n",
        "\n",
        "# Highlight the A* path\n",
        "for (row, col) in path:\n",
        "    plt.plot(col, row, 'ro')  # Mark the path with red dots\n",
        "\n",
        "# Highlight the recommended products\n",
        "for product_id in recommendations:\n",
        "    for i in range(grid_size):\n",
        "        for j in range(grid_size):\n",
        "            if grid[i, j] == product_id:\n",
        "                plt.text(j, i, product_id, ha='center', va='center', fontsize=8, bbox=dict(facecolor='yellow', edgecolor='black', boxstyle='round,pad=0.3'))\n",
        "\n",
        "# Plot the path taken by A*\n",
        "for idx in range(len(path) - 1):\n",
        "    current_row, current_col = path[idx]\n",
        "    next_row, next_col = path[idx + 1]\n",
        "    plt.plot([current_col, next_col], [current_row, next_row], 'r-', linewidth=2)  # Plot the path with a red line\n",
        "\n",
        "# Create a legend with category colors\n",
        "handles = [mpatches.Patch(color=color, label=category) for category, color in category_colors.items()]\n",
        "plt.legend(handles=handles, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
        "\n",
        "plt.xlabel('Embedding-based Column Index')\n",
        "plt.ylabel('Hybrid Filtering-based Row Index')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization with A* path\n",
        "plt.figure(figsize=(20, 20))  # Adjusted figure size\n",
        "\n",
        "# Define colors for categories\n",
        "categories_unique = list(set(p['category'] for p in products_dict.values()))\n",
        "category_colors = {category: plt.cm.tab20(i / len(categories_unique)) for i, category in enumerate(categories_unique)}\n",
        "\n",
        "# Plot the grid cells with category colors\n",
        "for (row, col), product_id in np.ndenumerate(grid):\n",
        "    if product_id is not None:\n",
        "        product = products_dict[product_id]\n",
        "        color = category_colors[product['category']]\n",
        "        plt.scatter(col, row, color=color, marker='s')\n",
        "\n",
        "# Highlight the A* path\n",
        "path_x = [col for row, col in path]\n",
        "path_y = [row for row, col in path]\n",
        "plt.plot(path_x, path_y, 'ro-')\n",
        "\n",
        "# Highlight the recommended products\n",
        "for product_id in recommendations:\n",
        "    for i in range(grid_size):\n",
        "        for j in range(grid_size):\n",
        "            if grid[i, j] == product_id:\n",
        "                plt.scatter(j, i, color='yellow', marker='o', s=100)\n",
        "\n",
        "# Create a legend with category colors\n",
        "handles = [mpatches.Patch(color=color, label=category) for category, color in category_colors.items()]\n",
        "plt.legend(handles=handles, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
        "\n",
        "plt.xlabel('Embedding-based Column Index')\n",
        "plt.ylabel('Hybrid Filtering-based Row Index')\n",
        "plt.axis('off')  # Turn off the axis\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization with A* path\n",
        "plt.figure(figsize=(20, 20))  # Adjusted figure size\n",
        "\n",
        "# Define colors for categories\n",
        "categories_unique = list(set(p['category'] for p in products_dict.values()))\n",
        "category_colors = {category: plt.cm.tab20(i / len(categories_unique)) for i, category in enumerate(categories_unique)}\n",
        "\n",
        "# Plot the grid cells with category colors\n",
        "for (row, col), product_id in np.ndenumerate(grid):\n",
        "    if product_id is not None:\n",
        "        product = products_dict[product_id]\n",
        "        color = category_colors[product['category']]\n",
        "        plt.scatter(col, row, color=color, marker='s')\n",
        "\n",
        "# Highlight the recommended products\n",
        "for product_id in recommendations:\n",
        "    for i in range(grid_size):\n",
        "        for j in range(grid_size):\n",
        "            if grid[i, j] == product_id:\n",
        "                product = products_dict[product_id]\n",
        "                color = category_colors[product['category']]\n",
        "                plt.scatter(j, i, color=color, marker='o', s=100)\n",
        "\n",
        "# Highlight the A* path\n",
        "path_x = [col for row, col in path]\n",
        "path_y = [row for row, col in path]\n",
        "plt.plot(path_x, path_y, 'ro-', linewidth=2)  # Highlight the path with red lines\n",
        "\n",
        "# Create a legend with category colors\n",
        "handles = [mpatches.Patch(color=color, label=category) for category, color in category_colors.items()]\n",
        "plt.legend(handles=handles, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
        "\n",
        "plt.xlabel('Embedding-based Column Index')\n",
        "plt.ylabel('Hybrid Filtering-based Row Index')\n",
        "plt.axis('off')  # Turn off the axis\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
